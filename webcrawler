#!/usr/bin/python3 -u

import socket
import urllib.parse as urlparser
import sys
import time
from html.parser import HTMLParser

# Global variables
visited = []
queue = []
flags = []
csrf = None
middleware = None
session = None

# Handle parsing HTML. Example referenced from html.parser documentation.


class WebCrawlerHTMLParser(HTMLParser):
    def handle_starttag(self, tag, attrs):
        global middleware
        # Find middleware token.
        if tag == 'input' and ('name', 'csrfmiddlewaretoken') in attrs:
          for attr in attrs:
            if attr[0] == 'value':
              middleware = attr[1]
        # Check for links
        for attr in attrs:
          if len(attrs) == 1 and len(attr) == 2:
            if attr[0] == 'href' and '/fakebook/' in attr[1]:
              if attr[1] not in visited:
                queue.append(attr[1])

    #def handle_endtag(self, tag):

    def handle_data(self, data):
      if "FLAG:" in data:
        if data[6:] not in flags:
          print(data[6:])
          flags.append(data[6:])

parser = WebCrawlerHTMLParser()

# Handle command line arguments.
if len(sys.argv) != 3:
    print("Command line arguments must be only username and password.")
    sys.exit(1)

username = sys.argv[1]
password = sys.argv[2]

# Parse HTTP Responses.
# TODO


def parseResponse(resp):
    resp = resp.rstrip()
    data = resp.split("\r\n\r\n")
    # Response header is first item of response.
    header = data[0].split("\r\n")
    # Response status is after first space of header.
    status = header[0].split(" ")[1]
    body = ""
    if len(data) >= 2:
        body = data[1]
    result = {'Header': header, 'Status': status, 'Body': body}

    # Parse all items of header.
    for i in range(1, len(header)):
        item = header[i].split(": ")
        # There may be multiple set cookies.
        if item[0] in result:
            result[item[0]] += ' | ' + item[1]
        else:
            result[item[0]] = item[1]

    # Handle cookies.
    if 'Set-Cookie' in result.keys():
        set_cookie = result['Set-Cookie']
        cookies = set_cookie.split(' | ')
        cookie_data = {}
        for cookie in cookies:
            cookie_split = cookie.split("; ")
            if 'Cookie-String' in result:
                result['Cookie-String'] += "; " + cookie_split[0]
            else:
                result['Cookie-String'] = cookie_split[0]
            data_split = cookie_split[0].split("=")
            cookie_data[data_split[0]] = data_split[1]
        result['Cookie-Data'] = cookie_data

    return result


# Connect to socket and login.
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sock.settimeout(1)
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
sock.connect(('webcrawler-site.ccs.neu.edu', 80))
sock.send('GET /accounts/login/ HTTP/1.1\r\nHost: webcrawler-site.ccs.neu.edu\r\n\r\n'.encode())
login_resp = sock.recv(500000).decode()
login_parsed = parseResponse(login_resp)


while login_parsed['Status'] != '200':
    sock.connect(('webcrawler-site.ccs.neu.edu', 80))
    sock.send('GET /accounts/login/ HTTP/1.1\r\nHost: webcrawler-site.ccs.neu.edu\r\n\r\n'.encode())
    login_resp = sock.recv(50000).decode()
    login_parsed = parseResponse(login_resp)

csrf = login_parsed['Cookie-Data']['csrftoken']
parser.feed(login_parsed['Body'])

post_params = 'username=' + username + '&password=' + password + '&csrfmiddlewaretoken=' + middleware + '&next=/fakebook/'
post_msg = ('POST /accounts/login/ HTTP/1.1\r\n'
            'Host: webcrawler-site.ccs.neu.edu\r\n'
            'Cookie: ' + login_parsed['Cookie-String'] + '\r\n'
            'Content-Type: application/x-www-form-urlencoded\r\n'
            'Content-Length: ' + str(len(post_params)) + '\r\n\r\n'
            + post_params)
sock.send(post_msg.encode())
post_resp = sock.recv(500000).decode()
post_parsed = parseResponse(post_resp)

csrf = post_parsed['Cookie-Data']['csrftoken']
session = post_parsed['Cookie-Data']['sessionid']



def login():
    global csrf
    global sock
    global session

    sock.close()
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

    sock.connect(('webcrawler-site.ccs.neu.edu', 80))
    sock.send('GET /accounts/login/ HTTP/1.1\r\nHost: webcrawler-site.ccs.neu.edu\r\n\r\n'.encode())
    login_resp = sock.recv(500000).decode()
    login_parsed = parseResponse(login_resp)

    while login_parsed['Status'] != '200':
        sock.connect(('webcrawler-site.ccs.neu.edu', 80))
        sock.send(
            'GET /accounts/login/ HTTP/1.1\r\nHost: webcrawler-site.ccs.neu.edu\r\n\r\n'.encode())
        login_resp = sock.recv(50000).decode()
        login_parsed = parseResponse(login_resp)

    csrf = login_parsed['Cookie-Data']['csrftoken']
    post_params = 'username=' + username + '&password=' + password + '&csrfmiddlewaretoken=' + middleware + '&next=/fakebook/'
    post_msg = ('POST /accounts/login/ HTTP/1.1\r\n'
                'Host: webcrawler-site.ccs.neu.edu\r\n'
                'Cookie: ' + login_parsed['Cookie-String'] + '\r\n'
                'Content-Type: application/x-www-form-urlencoded\r\n'
                'Content-Length: ' + str(len(post_params)) + '\r\n\r\n'
                + post_params + '\r\n\r\n')
    sock.send(post_msg.encode())
    post_resp = sock.recv(500000).decode()
    post_parsed = parseResponse(post_resp)
    while post_parsed['Status'] != '302':
        sock.send(post_msg.encode())
        post_resp = sock.recv(500000).decode()
        post_parsed = parseResponse(post_resp)
    csrf = post_parsed['Cookie-Data']['csrftoken']
    session = post_parsed['Cookie-Data']['sessionid']


def HTTPGet(path):
    cookie = "csrftoken=%s; sessionid=%s" % (csrf, session)

    new_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    new_socket.settimeout(1)
    new_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    new_socket.connect(('webcrawler-site.ccs.neu.edu', 80))
    get_msg = 'GET %s HTTP/1.1\r\nHost: webcrawler-site.ccs.neu.edu\r\nCookie: %s\r\n\r\n' % (path, cookie)
    new_socket.send(get_msg.encode())
    time.sleep(.05)

    resp = new_socket.recv(10000000).decode()

    check = resp.split('\r\n')
    if check[0] == '0' or len(resp) == 0:
        while check[0] == '0' or len(resp) == 0:
            new_socket.close()

            new_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            login()

            sock.send(get_msg.encode())
            time.sleep(.05)            

            resp = sock.recv(10000000).decode()

            check = resp.split('\r\n')  
    parsed_resp = parseResponse(resp)

    new_socket.shutdown(1)
    new_socket.close()
    return parsed_resp

home_path = '/fakebook/'

after_login = HTTPGet(home_path)
visited.append(home_path)
parser.feed(after_login['Body'])

def crawl():
    page = queue.pop()

    if page in visited:
      return

    try:
      page_html = HTTPGet(page)

      if page_html['Status'] == '200':
        parser.feed(page_html['Body'])
        visited.append(page)
      # If internal server error, try again later.
      elif page_html['Status'] == '500':
        login()
        queue.append(page)
      # If page doesn't exist, don't need to parse.
      elif page_html['Status'] == '403' or page_html['Status'] == '404':
        visited.append(page)
      # If redirect, try to add new link to queue.
      elif page_html['Status'] == '301':
        new_link = page_html['Location']
        if new_link not in visited and new_link[0:10] == '/fakebook/':
          queue.append(new_link)
      else:
        print("Unexpected error.")
    # If socket timed out, try again later.
    except socket.timeout:
      queue.append(page)

while len(flags) < 5 and len(queue) > 0:
  crawl()



