#!/usr/bin/python3 -u

import socket
import urllib.parse as urlparser
import sys
from html.parser import HTMLParser

# Global variables
visited = []
queue = []
flags = []
csrf = None
session = None

# Handle parsing HTML. Example referenced from html.parser documentation.
class WebCrawlerHTMLParser(HTMLParser):
  def handle_starttag(self, tag, attrs):
    for attr in attrs:
      print(attr)

  def handle_endtag(self, tag):
    print()

  def handle_data(self, data):
    print()
parser = WebCrawlerHTMLParser()

# Handle command line arguments.
if len(sys.argv) != 3:
  print("Command line arguments must be only username and password.")
  sys.exit(1)

username = sys.argv[1]
password = sys.argv[2]

# Parse HTTP Responses.
# TODO 
def parseResponse(resp):
    resp = resp.rstrip()
    data = resp.split("\r\n\r\n")
    # Response header is first item of response.
    header = data[0].split("\r\n")
    # Response status is after first space of header.
    status = header[0].split(" ")[1]
    body = ""
    if len(data) >= 2:
      body = data[1]
    result = {'Header': header, 'Status': status, 'Body': body}

    # Parse all items of header.
    for i in range(1, len(header)):
      item = header[i].split(": ")
      if item[0] in result:
        result[item[0]] += ' | ' + item[1]
      else:
        result[item[0]] = item[1]
    
    # Handle cookies.
    if 'Set-Cookie' in result.keys():
      set_cookie = result['Set-Cookie']
      cookies = set_cookie.split(' | ')
      cookie_data = {}
      for cookie in cookies:
        cookie_split = cookie.split("; ")
        if 'Cookie-String' in result:
          result['Cookie-String'] += "; " + cookie_split[0]
        else:
          result['Cookie-String'] = cookie_split[0]
        data_split = cookie_split[0].split("=")
        cookie_data[data_split[0]]: data_split[1]
      result['Cookie-Data'] = cookie_data
      print(result)
    
    return result

# Connect to socket and login.
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sock.settimeout(0.30)
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
sock.connect(('webcrawler-site.ccs.neu.edu', 80))
sock.send('GET /accounts/login/?next=/fakebook/ HTTP/1.1\r\nHost: webcrawler-site.ccs.neu.edu\r\n\r\n'.encode())
login_resp = sock.recv(500000).decode()
login_parsed = parseResponse(login_resp)

while login_parsed['Status'] != '200':
  sock.connect(('webcrawler-site.ccs.neu.edu', 80))
  sock.send('GET /accounts/login/?next=/fakebook/ HTTP/1.1\r\nHost: webcrawler-site.ccs.neu.edu\r\n\r\n'.encode())
  login_resp = sock.recv(50000).decode()
  login_parsed = parseResponse(login_resp)

csrf = login_parsed['Cookie-Data']['csrftoken']
session = login_parsed['Cookie-Data']['sessionid']
post_params = 'username=' + username + '&password=' + password + '&csrfmiddlewaretoken=' + csrf  + '&next=/fakebook/'
sock.send('POST /accounts/login/?next=/fakebook/ HTTP/1.1\r\n'
                'Host: webcrawler-site.ccs.neu.edu\r\n'
                'Cookie: ' + login_parsed['Cookie_string'] + '\r\n' 
                'Content-Type: application/x-www-form-urlencoded\r\n'
                'Content-Length: ' + str(len(post_params)) + '\r\n\r\n'
                + post_params + '\r\n\r\n')
post_resp = sock.recv(50000)
post_parsed = parseResponse(post_resp)
while post_parsed['Status'] != '302':
  sock.send('POST /accounts/login/?next=/fakebook/ HTTP/1.1\r\n'
                  'Host: webcrawler-site.ccs.neu.edu\r\n'
                  'Cookie: ' + login_parsed['Cookie_string'] + '\r\n' 
                  'Content-Type: application/x-www-form-urlencoded\r\n'
                  'Content-Length: ' + str(len(post_params)) + '\r\n\r\n'
                + post_params + '\r\n\r\n')
  post_resp = sock.recv(50000)
  post_parsed = parseResponse(post_resp)
session = post_parsed['Cookie-Data']['sessionid']

def HTTPGet(path):
  cookie = "csrftoken=%s; sessionid=%s" % (csrf, session)

  new_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
  new_socket.settimeout(0.30)
  new_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
  new_socket.connect(('webcrawler-site.ccs.neu.edu', 80))
  new_socket.send('Get %s HTTP/1.1\nHost: webcrawler-site.ccs.neu.edu\n%s\r\n\r\n' % (path, cookie))

  resp = new_socket.recv(10000000)
  parsed_resp = parseResponse(resp)

  new_socket.shutdown(1)
  new_socket.close()
  return parsed_resp

home_url = urlparser.urlparse(post_parsed['Location'])
home_path = home_url.path
if home_path == "":
    home_path = "/"

if home_url.query:
    home_path += '?' + home_url.query

after_login = HTTPGet(home_path)
visited.append(home_path)
parser.feed(after_login['Body'])

def crawl():
  page = queue.pop()



